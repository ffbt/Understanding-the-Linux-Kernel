### 4.7 软中断及 tasklet

软中断和 tasklet 的比较

|  类型  |                       软中断                       |                     tasklet                      |
| :----: | :------------------------------------------------: | :----------------------------------------------: |
|  分配  |                   静态（编译时）                   |                  动态（运行时）                  |
| 并发性 | 同一类型可以并发，可重入，需要用自旋锁保护数据结构 | 同一类型串行执行，不同类型可以并发，不必是可重入 |

#### 4.7.1 软中断

##### 4.7.1.1 软中断所使用的数据结构

```c
struct softirq_action
{
	void	(*action)(struct softirq_action *);
	void	*data;
};
```

```c
#define in_interrupt()		(irq_count())
#define irq_count()	(preempt_count() & (HARDIRQ_MASK | SOFTIRQ_MASK))
```

```c
#define local_softirq_pending() \
	__IRQ_STAT(smp_processor_id(), __softirq_pending)
#define __IRQ_STAT(cpu, member)	(irq_stat[cpu].member)
```

##### 4.7.1.2 处理软中断

```c
// 处理软中断的初始化
void open_softirq(int nr, void (*action)(struct softirq_action*), void *data)
{
	softirq_vec[nr].data = data;
	softirq_vec[nr].action = action;
}
```

```c
// 激活软中断
void fastcall raise_softirq(unsigned int nr)
{
	unsigned long flags;

    // 对 local_irq_save 的调用将把当前中断状态保存到 flags 中，然后禁用当前处理器上的中断发送。注意, flags 被直接传递, 而不是通过指针来传递。 
	local_irq_save(flags);		// 1
	raise_softirq_irqoff(nr);	// ->
	local_irq_restore(flags);
}

#define local_irq_save(x)	__asm__ __volatile__("pushfl ; popl %0 ; cli":"=g" (x): /* no input */ :"memory")
    
#define local_irq_restore(x) 	do { typecheck(unsigned long,x); __asm__ __volatile__("pushl %0 ; popfl": /* no output */ :"g" (x):"memory", "cc"); } while (0)
```

```c
inline fastcall void raise_softirq_irqoff(unsigned int nr)
{
    // #define __raise_softirq_irqoff(nr) do { local_softirq_pending() |= 1UL << (nr); } while (0)
	__raise_softirq_irqoff(nr);

	/*
	 * If we're in an interrupt or softirq, we're done
	 * (this also catches softirq-disabled code). We will
	 * actually run the softirq once we return from
	 * the irq or softirq.
	 *
	 * Otherwise we wake up ksoftirqd to make sure we
	 * schedule the softirq soon.
	 */
	if (!in_interrupt())	// 3
		wakeup_softirqd();		// ->
}
```

```c
static inline void wakeup_softirqd(void)
{
	/* Interrupts are disabled: no need to stop preemption */
	struct task_struct *tsk = __get_cpu_var(ksoftirqd);

	if (tsk && tsk->state != TASK_RUNNING)
		wake_up_process(tsk);
}
```

##### 4.1.7.3 `do_softirq()` 函数

```c
// 处理挂起的软中断
asmlinkage void do_softirq(void)
{
	unsigned long flags;
	struct thread_info *curctx;
	union irq_ctx *irqctx;
	u32 *isp;

	if (in_interrupt())		// 1
		return;

	local_irq_save(flags);	// 2

	if (local_softirq_pending()) {		// 3
		curctx = current_thread_info();
		irqctx = softirq_ctx[smp_processor_id()];
		irqctx->tinfo.task = curctx->task;
		irqctx->tinfo.previous_esp = current_stack_pointer;

		/* build the stack frame on the softirq stack */
		isp = (u32*) ((char*)irqctx + sizeof(*irqctx));

		asm volatile(
			"       xchgl   %%ebx,%%esp     \n"
			"       call    __do_softirq    \n"		// 4
			"       movl    %%ebx,%%esp     \n"		// 5
			: "=b"(isp)
			: "0"(isp)
			: "memory", "cc", "edx", "ecx", "eax"
		);
	}

	local_irq_restore(flags);	// 6
}
```

##### 4.1.7.4 `__do_softirq()` 函数

```c
asmlinkage void __do_softirq(void)
{
	struct softirq_action *h;
	__u32 pending;
    // #define MAX_SOFTIRQ_RESTART 10
	int max_restart = MAX_SOFTIRQ_RESTART;		// 1
	int cpu;

	pending = local_softirq_pending();		// 2

	local_bh_disable();		// 3	->
	cpu = smp_processor_id();
restart:
	/* Reset the pending bitmask before enabling irqs */
	local_softirq_pending() = 0;	// 4

	local_irq_enable();		// 5

	h = softirq_vec;

	do {	// 6
		if (pending & 1) {
			h->action(h);
			rcu_bh_qsctr_inc(cpu);
		}
		h++;
		pending >>= 1;
	} while (pending);

	local_irq_disable();	// 7

	pending = local_softirq_pending();		// 8
	if (pending && --max_restart)
		goto restart;	// 9

	if (pending)
		wakeup_softirqd();		// 10

	__local_bh_enable();	// 11
}
```

```c
#define local_bh_disable() \
		do { add_preempt_count(SOFTIRQ_OFFSET); barrier(); } while (0)
```

##### 4.1.7.5 `ksoftirqd` 内核线程

```c
static int ksoftirqd(void * __bind_cpu)
{
	set_user_nice(current, 19);
	current->flags |= PF_NOFREEZE;

	set_current_state(TASK_INTERRUPTIBLE);

	while (!kthread_should_stop()) {
		if (!local_softirq_pending())
			schedule();

		__set_current_state(TASK_RUNNING);

		while (local_softirq_pending()) {
			/* Preempt disable stops cpu going offline.
			   If already offline, we'll be on wrong CPU:
			   don't process */
			preempt_disable();
			if (cpu_is_offline((long)__bind_cpu))
				goto wait_to_die;
			do_softirq();
			preempt_enable();
			cond_resched();
		}

		set_current_state(TASK_INTERRUPTIBLE);
	}
	__set_current_state(TASK_RUNNING);
	return 0;

wait_to_die:
	preempt_enable();
	/* Wait for kthread_stop */
	set_current_state(TASK_INTERRUPTIBLE);
	while (!kthread_should_stop()) {
		schedule();
		set_current_state(TASK_INTERRUPTIBLE);
	}
	__set_current_state(TASK_RUNNING);
	return 0;
}
```

#### 4.7.2 tasklet

